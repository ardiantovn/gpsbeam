{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('F:/repo/gpsbeam')\n",
    "\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import timeit\n",
    "import concurrent\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "from src.config.data_config import DataConfig\n",
    "from src.data.dataprep import DataPrep\n",
    "from src.data.base_datatotensor import BaseDataToTensor\n",
    "from src.preprocessor.gpsprep import GpsPrep\n",
    "\n",
    "from src.config.data_config import DataConfig\n",
    "from src.config.cnn_ed_rnn_model_config import ModelConfig\n",
    "from src.config.experiment_config import ExperimentConfig\n",
    "from src.modelprep import ModelPrep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-20 15:26:06.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data.dataprep\u001b[0m:\u001b[36mget_train_val_test_dataset\u001b[0m:\u001b[36m296\u001b[0m - \u001b[1m\n",
      "Dataset is LOADED from f:/repo/gpsbeam\\data/processed/Scenario23/dset_scenario23_seednum42_train0.65_test0.2_portion100_beam32_splitting_method_adjusted.hkl\u001b[0m\n",
      "\u001b[32m2025-05-20 15:26:06.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data.dataprep\u001b[0m:\u001b[36mget_train_val_test_dataset\u001b[0m:\u001b[36m311\u001b[0m - \u001b[1m\n",
      "                    RAW DATASET INFO\n",
      "                    ------------------------------\n",
      "                    Scenario Num                                    : 23,\n",
      "                    Splitting Method                                : adjusted\n",
      "                    Portion Percentage                              : 100\n",
      "                    Training                                        : 7387 samples [64.87%]\n",
      "                    Validation                                      : 1694 samples [14.88%]\n",
      "                    Testing                                         : 2306 samples [20.25%]\n",
      "                    Total                                           : 11387 samples\n",
      "\u001b[0m\n",
      "\u001b[32m2025-05-20 15:26:06.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data.dataprep\u001b[0m:\u001b[36mget_train_val_test_dataset\u001b[0m:\u001b[36m321\u001b[0m - \u001b[1m------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data_config_obj = DataConfig(train_val_test_split_frac=[0.65, 0.15, 0.2], \n",
    "                             splitting_method='adjusted',\n",
    "                             num_classes=32,\n",
    "                             scenario_num=23)\n",
    "\n",
    "dataprep_obj = DataPrep(data_config_obj)\n",
    "\n",
    "dataprep_obj.get_train_val_test_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Trained Pytorch & ONNX Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ONNX model\n",
    "torch_fname = r'F:\\repo\\gpsbeam\\data\\experiment_result\\00_test_drone_cnn_ed_rnn_experiment_20052025_151107\\05-20-2025_15_11_29\\dl_generated\\model_checkpoint\\arch_cnn-ed-gru-model_nclass_32_.pth'\n",
    "onnx_fname = r'F:\\repo\\gpsbeam\\data\\experiment_result\\00_test_drone_cnn_ed_rnn_experiment_20052025_151107\\05-20-2025_15_11_29\\dl_generated\\model_checkpoint\\arch_cnn-ed-gru-model_nclass_32_.onnx'\n",
    "ort_session = ort.InferenceSession(onnx_fname,\n",
    "                                   providers=[\"CPUExecutionProvider\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-20 15:28:10.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.modelprep\u001b[0m:\u001b[36m_setup_paths\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mmodel_recap_dir Name: f:/repo/gpsbeam\\data/experiment_result/00_test_drone_cnn_ed_rnn_experiment_20052025_152810/model_recap\u001b[0m\n",
      "\u001b[32m2025-05-20 15:28:10.611\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.preprocessor.gpsprep\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m8\u001b[0m - \u001b[34m\u001b[1mGpsPrep Initialized.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_config_obj=ModelConfig(model_arch_name='cnn-ed-gru-model',\n",
    "                                       train_epoch=20,\n",
    "                                       train_batch_size=8,\n",
    "                                       test_batch_size=1024,\n",
    "                                       use_early_stopping=False,\n",
    "                                       device='cpu',\n",
    "                                       model_input_column_list=['unit2to1_vector', 'unit2_height_log'],\n",
    "                                       zero_pad_nonconsecutive=True,\n",
    "                                       ends_input_with_out_len_zeros=False,\n",
    "                                       seq_len=8,\n",
    "                                       out_len=3,\n",
    "                                       cnn_channels=[128, 128],\n",
    "                                       rnn_num_layers=1,\n",
    "                                       rnn_hidden_size=128,\n",
    "                                       mlp_layer_sizes=[64],\n",
    "                                       rnn_dropout=0, # fix\n",
    "                                       cnn_dropout=0, # fix\n",
    "                                       adam_weight_decay=0, # fix\n",
    "                                       loss_func_name='cross-entropy-loss',\n",
    "                                       adam_learning_rate=5e-4, # fix\n",
    "                                       adam_opt_milestone_list=[12, 18],\n",
    "                                       num_classes=32\n",
    "                                       )\n",
    "\n",
    "exp_config_obj=ExperimentConfig(\n",
    "                  exp_folder_name='00_test_drone_cnn_ed_rnn_experiment',\n",
    "                  exp_dict={\n",
    "                      \"model_arch_name\": ['cnn-ed-gru-model'\n",
    "                                        ],\n",
    "                       \"num_classes\": [32]\n",
    "                  })\n",
    "\n",
    "modelprep_obj = ModelPrep(experiment_config=exp_config_obj,\n",
    "                                    data_config=data_config_obj,\n",
    "                                    model_config=model_config_obj,\n",
    "                                    dataset_dict=dataprep_obj.dataset_dict)\n",
    "\n",
    "modelprep_obj._setup_model()\n",
    "modelprep_obj.model.load_state_dict(torch.load(torch_fname))\n",
    "\n",
    "test_dataset = modelprep_obj._create_tensor_dataset(data_dict=dataprep_obj.dataset_dict['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show an Example of Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_from_scenario': tensor([ 0,  0,  0,  0, 23, 23, 23, 23]),\n",
       " 'input_seq_idx': tensor([0, 0, 0, 0, 1, 1, 1, 1]),\n",
       " 'input_speed': tensor([0.0000, 0.0000, 0.0000, 0.0000, 7.6056, 6.4871, 5.8160, 4.6976]),\n",
       " 'input_height': tensor([  0.0000,   0.0000,   0.0000,   0.0000, 103.6745, 103.6745, 103.6745,\n",
       "         103.6745]),\n",
       " 'input_value': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.3218, -0.7464,  0.5825,  4.6509],\n",
       "         [-0.3247, -0.7451,  0.5826,  4.6509],\n",
       "         [-0.3270, -0.7440,  0.5827,  4.6509],\n",
       "         [-0.3297, -0.7427,  0.5829,  4.6509]]),\n",
       " 'input_beam_idx': tensor([ 0,  0,  0,  0, 14, 14, 14, 14]),\n",
       " 'input_pitch': tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -3.4000, -3.3000, -2.8000, -1.4000]),\n",
       " 'input_roll': tensor([ 0.0000,  0.0000,  0.0000,  0.0000, 13.1000, 12.6000, 12.2000,  9.5000]),\n",
       " 'label': tensor([14, 14, 14, 14]),\n",
       " 'future_sample_idx': tensor([206, 207, 208, 209]),\n",
       " 'input_sample_idx': tensor([  0,   0,   0,   0, 203, 204, 205, 206])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Time Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX inference time: 0.1992 ms\n",
      "PyTorch inference time: 1.1623 ms\n",
      "ONNX is 5.83x faster than PyTorch\n",
      "ONNX top 5 beam indices: [[14 15 16 13 18]\n",
      " [14 15 16 13 18]\n",
      " [14 15 13 16 18]\n",
      " [14 15 16 13 18]]\n",
      "PyTorch top 5 beam indices: [[14 15 13 16 18]\n",
      " [14 15 13 16 19]\n",
      " [14 15 13 16 19]\n",
      " [14 15 13 16 19]]\n"
     ]
    }
   ],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# Apply softmax to the raw output to get probabilities\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each set of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))  # Subtract max for numerical stability\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def get_top_5_beams_inference_time(sample, num_iteration):\n",
    "    \"\"\"\n",
    "    Get top 5 beam predictions and measure inference time for both ONNX and PyTorch models\n",
    "    \n",
    "    Args:\n",
    "        sample: Input tensor sample\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (onnx_indices, torch_indices, onnx_time_ms, torch_time_ms)\n",
    "    \"\"\"\n",
    "    def onnx_inference():\n",
    "        # Reshape input for ONNX model (add batch dimension)\n",
    "        input_reshaped = sample.unsqueeze(0)\n",
    "        \n",
    "        # Run ONNX inference\n",
    "        ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(input_reshaped)}\n",
    "        ort_outs = ort_session.run(['output'], ort_inputs)\n",
    "        \n",
    "        # Get probabilities from logits\n",
    "        all_pred_steps = ort_outs[0][0] # 4 prediction step\n",
    "        \n",
    "        # Apply softmax to all predictions at once\n",
    "        probabilities_all = softmax(all_pred_steps)\n",
    "        # Get top 5 indices for all predictions at once\n",
    "        top_5_beams_all = np.argsort(probabilities_all, axis=1)[:, ::-1][:, :5]\n",
    "        # Convert to list of arrays\n",
    "        # all_pred_sorted = [top_5_beams_all[i] for i in range(len(top_5_beams_all))]\n",
    "        return top_5_beams_all\n",
    "\n",
    "    def torch_inference():\n",
    "        # Reshape input for PyTorch model\n",
    "        input_reshaped = sample.unsqueeze(0)\n",
    "        \n",
    "        # Run PyTorch inference\n",
    "        with torch.no_grad():\n",
    "            outputs= modelprep_obj.model(input_reshaped)\n",
    "            all_pred_steps = outputs[0][0] # 4 prediction step\n",
    "            \n",
    "            # Convert all predictions to numpy at once\n",
    "            logits_all = all_pred_steps.numpy()\n",
    "            # Apply softmax to all predictions at once\n",
    "            probabilities_all = softmax(logits_all)\n",
    "            # Get top 5 indices for all predictions at once\n",
    "            top_5_beams_all = np.argsort(probabilities_all, axis=1)[:, ::-1][:, :5]\n",
    "            # Add each prediction's top 5 beams to the result list\n",
    "            # all_pred_sorted = [top_5_beams_all[i] for i in range(len(top_5_beams_all))]\n",
    "            return top_5_beams_all\n",
    "    \n",
    "    # Measure ONNX inference time\n",
    "    onnx_time_ms = timeit.timeit(onnx_inference, number=num_iteration) * 1000 / num_iteration\n",
    "    \n",
    "    # Measure PyTorch inference time  \n",
    "    torch_time_ms = timeit.timeit(torch_inference, number=num_iteration) * 1000 / num_iteration\n",
    "    \n",
    "    # Run once more to get actual indices\n",
    "    onnx_indices = onnx_inference()\n",
    "    torch_indices = torch_inference()\n",
    "    \n",
    "    return onnx_indices, torch_indices, onnx_time_ms, torch_time_ms\n",
    "\n",
    "# Test the function\n",
    "num_iteration = 10_000\n",
    "sample = test_dataset[0]['input_value']\n",
    "onnx_indices, torch_indices, onnx_time_ms, torch_time_ms = get_top_5_beams_inference_time(sample, num_iteration)\n",
    "print(f\"ONNX inference time: {onnx_time_ms:.4f} ms\")\n",
    "print(f\"PyTorch inference time: {torch_time_ms:.4f} ms\")\n",
    "print(f\"ONNX is {torch_time_ms/onnx_time_ms:.2f}x faster than PyTorch\")\n",
    "print(f\"ONNX top 5 beam indices: {onnx_indices}\")\n",
    "print(f\"PyTorch top 5 beam indices: {torch_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Output Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.3218, -0.7464,  0.5825,  4.6509],\n",
      "        [-0.3247, -0.7451,  0.5826,  4.6509],\n",
      "        [-0.3270, -0.7440,  0.5827,  4.6509],\n",
      "        [-0.3297, -0.7427,  0.5829,  4.6509]])\n",
      "sample.shape: torch.Size([8, 4])\n",
      "input_reshaped.shape: torch.Size([1, 8, 4])\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.3218, -0.7464,  0.5825,  4.6509],\n",
      "         [-0.3247, -0.7451,  0.5826,  4.6509],\n",
      "         [-0.3270, -0.7440,  0.5827,  4.6509],\n",
      "         [-0.3297, -0.7427,  0.5829,  4.6509]]])\n",
      "Sum of probabilities: 1.0\n",
      "Predicted beam index: 14\n",
      "Probability of predicted beam: 0.538693\n",
      "\n",
      "Top beams until 80.0% confidence:\n",
      "Beam 14: 0.538693\n",
      "Beam 15: 0.307830\n",
      "Number of beams needed to reach 80.0% confidence: 2\n"
     ]
    }
   ],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# Apply softmax to the raw output to get probabilities\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each set of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))  # Subtract max for numerical stability\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "# Get the predicted class (beam index with highest probability)\n",
    "def get_top_beams_until_threshold(probabilities, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Get the top beam indices until their cumulative probability reaches the threshold.\n",
    "    \n",
    "    Args:\n",
    "        probabilities: Array of probabilities for each beam\n",
    "        threshold: Probability threshold (default: 0.8)\n",
    "        \n",
    "    Returns:\n",
    "        List of (beam_index, probability) tuples and the total number of beams needed\n",
    "    \"\"\"\n",
    "    # Sort probabilities in descending order and get corresponding indices\n",
    "    sorted_indices = np.argsort(probabilities)[::-1]\n",
    "    sorted_probs = probabilities[sorted_indices]\n",
    "    \n",
    "    # Find how many beams we need to reach the threshold\n",
    "    cumulative_sum = 0\n",
    "    selected_beams = []\n",
    "    \n",
    "    for i, (idx, prob) in enumerate(zip(sorted_indices, sorted_probs)):\n",
    "        cumulative_sum += prob\n",
    "        selected_beams.append((idx, prob))\n",
    "        \n",
    "        if cumulative_sum > threshold:\n",
    "            break\n",
    "    \n",
    "    return selected_beams, len(selected_beams)\n",
    "\n",
    "# The ONNX model expects input with rank 3 (batch_size, sequence_length, features)\n",
    "# Reshape the input tensor to add batch dimension and sequence dimension\n",
    "sample = test_dataset[0]['input_value']\n",
    "print(sample)\n",
    "print(f\"sample.shape: {sample.shape}\")\n",
    "input_reshaped = sample.unsqueeze(0)  # Add batch dimension\n",
    "# input_reshaped = input_reshaped.unsqueeze(0)  # Add sequence dimension\n",
    "print(f\"input_reshaped.shape: {input_reshaped.shape}\")\n",
    "print(input_reshaped)\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(input_reshaped)}\n",
    "ort_outs, h = ort_session.run(None, ort_inputs)\n",
    "\n",
    "\n",
    "all_pred_steps = ort_outs[0] # 4 prediction step\n",
    "logits = all_pred_steps[0] # 1st prediction step\n",
    "\n",
    "# Apply softmax to convert logits to probabilities\n",
    "probabilities = softmax(logits)\n",
    "\n",
    "print(f\"Sum of probabilities: {np.sum(probabilities)}\")  # Should be close to 1.0\n",
    "\n",
    "# Get the predicted beam with highest probability\n",
    "predicted_beam = np.argmax(probabilities)\n",
    "print(f\"Predicted beam index: {predicted_beam}\")\n",
    "print(f\"Probability of predicted beam: {probabilities[predicted_beam]:.6f}\")\n",
    "\n",
    "# Get top beams until threshold\n",
    "threshold = 0.8\n",
    "top_beams, num_beams_needed = get_top_beams_until_threshold(probabilities, threshold)\n",
    "\n",
    "print(f\"\\nTop beams until {threshold*100}% confidence:\")\n",
    "for beam_idx, prob in top_beams:\n",
    "    print(f\"Beam {beam_idx}: {prob:.6f}\")\n",
    "print(f\"Number of beams needed to reach {threshold*100}% confidence: {num_beams_needed}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geobeam-3fwD9wo9-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
